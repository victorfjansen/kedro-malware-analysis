import boto3
from kedro.io import AbstractDataset
from PIL import Image
import os
import io

class S3MultipleImageFolderDataSet(AbstractDataset):
    def __init__(self, bucket_name: str, folder_prefix: str, credentials=None,aws_access_key_id=None, aws_secret_access_key=None, region_name=None):
        """
        :param bucket_name: Name of the S3 bucket.
        :param folder_prefix: The common folder (prefix) inside the S3 bucket where images are stored. 
                              It can be the root (empty string) or a higher-level folder.
        :param aws_access_key_id: AWS access key ID.
        :param aws_secret_access_key: AWS secret access key.
        :param region_name: AWS region.
        """
        
        print("CREEEDENTIAAAALSSS", credentials)
        self.bucket_name = bucket_name
        self.folder_prefix = folder_prefix.rstrip('/') + '/'
        self.s3 = boto3.client(
            's3',
            aws_access_key_id=credentials.client_kwargs.aws_access_key_id,
            aws_secret_access_key=credentials.client_kwargs.aws_secret_access_key,
            region_name=region_name
        )

    def _load(self) -> dict:
        """
        Loads images from multiple folders (prefixes) in the S3 bucket.
        :return: A dictionary where keys are categories (folder names), and values are lists of images.
        """
        # List all objects with the specified folder prefix
        response = self.s3.list_objects_v2(Bucket=self.bucket_name, Prefix=self.folder_prefix, Delimiter='/')
        categories = {}

        # Loop through each folder (common prefix)
        for folder in response.get('CommonPrefixes', []):
            category = os.path.basename(folder['Prefix'].rstrip('/'))
            categories[category] = []

            # Get images within the folder
            folder_contents = self.s3.list_objects_v2(Bucket=self.bucket_name, Prefix=folder['Prefix'])
            for obj in folder_contents.get('Contents', []):
                if obj['Key'].endswith(('.jpg', '.jpeg', '.png')):  # Filter only image files
                    image_obj = self.s3.get_object(Bucket=self.bucket_name, Key=obj['Key'])
                    image_data = image_obj['Body'].read()
                    image = Image.open(io.BytesIO(image_data))
                    categories[category].append(image)

        return categories

    def _save(self, data) -> None:
        raise NotImplementedError("Saving is not supported for this dataset")

    def _describe(self) -> dict:
        return dict(bucket_name=self.bucket_name, folder_prefix=self.folder_prefix)
